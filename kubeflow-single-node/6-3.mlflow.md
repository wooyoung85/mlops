# MLFlow Install

```bash
kubectl create ns mlflow
 
kubectl create -n mlflow secret generic mlflow-secret \
    --from-literal=AWS_ACCESS_KEY_ID='minio' \
    --from-literal=AWS_SECRET_ACCESS_KEY='minio123'
 
helm repo add bitnami https://charts.bitnami.com/bitnami

helm upgrade --install mlflow bitnami/mlflow -n mlflow --version 2.4.1 \
--set minio.enabled=false \
--set externalS3.host=minio.minio-system.svc.cluster.local \
--set externalS3.port=9000 \
--set externalS3.existingSecret=mlflow-secret \
--set externalS3.existingSecretAccessKeyIDKey="AWS_ACCESS_KEY_ID" \
--set externalS3.existingSecretKeySecretKey="AWS_SECRET_ACCESS_KEY" \
--set externalS3.bucket="mlflow" \
--set externalS3.protocol=http

# helm uninstall -n mlflow mlflow
# kubectl delete pvc -n mlflow data-mlflow-postgresql-0
# kubectl delete pvc -n mlflow mlflow-tracking

kubectl get po -n mlflow --watch

kubectl patch svc mlflow-tracking -n mlflow -p '{"spec":{"ports":[{"name":"http","port":80,"targetPort":"http","protocol":"TCP","nodePort":32003}]}}'

echo Username: $(kubectl get secret --namespace mlflow mlflow-tracking -o jsonpath="{ .data.admin-user }" | base64 -d) 
echo Password: $(kubectl get secret --namespace mlflow mlflow-tracking -o jsonpath="{.data.admin-password }" | base64 -d)

```

# Test

```py
# https://mlflow.org/docs/latest/getting-started/intro-quickstart/index.html
!pip install mlflow==2.20



import pandas as pd
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


# Load the Iris dataset
X, y = datasets.load_iris(return_X_y=True)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Define the model hyperparameters
params = {
    "solver": "lbfgs",
    "max_iter": 1000,
    "multi_class": "auto",
    "random_state": 8888,
}

# Train the model
lr = LogisticRegression(**params)
lr.fit(X_train, y_train)

# Predict on the test set
y_pred = lr.predict(X_test)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)


import mlflow
from mlflow.models import infer_signature
import os

os.environ['MLFLOW_TRACKING_USERNAME'] = 'user'
os.environ['MLFLOW_TRACKING_PASSWORD'] = 'lxnaoI9frw'

# Set our tracking server uri for logging
mlflow.set_tracking_uri(uri="http://mlflow-tracking.mlflow.svc.cluster.local")

# Create a new MLflow Experiment
mlflow.set_experiment("MLflow Quickstart")

# Start an MLflow run
with mlflow.start_run():
    # Log the hyperparameters
    mlflow.log_params(params)

    # Log the loss metric
    mlflow.log_metric("accuracy", accuracy)

    # Set a tag that we can use to remind ourselves what this run was for
    mlflow.set_tag("Training Info", "Basic LR model for iris data")

    # Infer the model signature
    signature = infer_signature(X_train, lr.predict(X_train))

    # Log the model
    model_info = mlflow.sklearn.log_model(
        sk_model=lr,
        artifact_path="iris_model",
        signature=signature,
        input_example=X_train,
        registered_model_name="tracking-quickstart",
    )


# Load the model back for predictions as a generic Python Function model
loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)

predictions = loaded_model.predict(X_test)

iris_feature_names = datasets.load_iris().feature_names

result = pd.DataFrame(X_test, columns=iris_feature_names)
result["actual_class"] = y_test
result["predicted_class"] = predictions

result[:4]
```