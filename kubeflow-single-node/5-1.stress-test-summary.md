
# 결론

주어진 자원(4Core CPU, 8GB 메모리)에서 Jupyter Notebook의 성능 한계

- CPU: 4Core CPU는 중간 수준의 병렬 작업(프로세스 4개 이하)에서는 안정적이지만, 6개 이상의 프로세스에서 성능 저하가 두드러지게 나타나면서 11개 프로세스에서 Kernel Dead 발생
- 메모리: 약 8.5GB까지의 부하를 견딜 수 있고 이후 Kernel Dead 발생 (단, 디스크 용량 부족 시 스왑이 제한되면서 더 빠르게 실패할 수 있음)
- 디스크: 5GB 디스크는 대용량 파일 작업에서 심각한 제약이 되며, 900MB 부터 한번에 쓰기 시도하면 Kernel Dead 발생

# 1. CPU 부하 테스트

## 테스트 케이스
- 목표: 컨테이너 환경에서 CPU 부하를 점진적으로 증가시켜 할당된 CPU 리소스의 한계를 테스트하고, 부하에 따른 사용량 및 응답성 측정
- 방법: 여러 개의 프로세스를 사용하여 CPU 집약적인 작업(예: 대규모 행렬 연산)을 수행합니다.
- 주요 모니터링 포인트:
  - **CPU 사용량(%)**: `Container CPU Usage` 출력 값을 통해 프로세스 수 증가에 따라 CPU 사용률이 어떻게 변하는지 확인. 이상적으로는 CPU 제한(cpu_limit)에 근접해야 함
  - **프로세스별 실행 시간**: 각 프로세스의 실행 시간을 확인하여 부하가 균등하게 분배되었는지 평가
  - **시스템 응답성**: 테스트 중 Kubeflow 또는 Jupyter Notebook의 반응 속도가 느려지거나 중단되는지 관찰하여 CPU 부하의 영향을 측정
  - **컨테이너 CPU 제한 반영 여부**: 컨테이너에 할당된 CPU 값과 실제 CPU 사용량이 일치하는지 확인하여 컨테이너 설정이 올바르게 적용되었는지 점검

```py
import multiprocessing
import numpy as np
import time
import psutil
import os

def cpu_worker(return_dict, process_id, duration):
    """CPU 부하 작업 실행 시간 측정"""
    ...

def get_container_cpu_limit():
    """컨테이너의 CPU 할당량 확인"""
    ...

def get_container_cpu_usage():
    """컨테이너의 CPU 사용량 확인"""
    ...

def cpu_stress_test(max_processes, step_duration=10):
    """
    Parameters:
    max_processes (int): 최대 프로세스 수
    step_duration (int): 각 단계의 지속 시간 (초)
    """
    ...

if __name__ == "__main__":
    cpu_stress_test(max_processes=8, step_duration=5)
```


# 2. 메모리 부하 테스트

## 테스트 케이스
- 목표: 메모리 사용량을 점진적으로 증가시켜 Jupyter Notebook의 안정성 평가
- 방법: `numpy` 로 랜덤 배열을 생성하고, 이를 `pandas` `DataFrame` 으로 변환 및 연산 수행
- 기준:
  - **메모리 사용량(MB)**: Memory Usage 출력 값이 단계별 예상 크기(size_mb)와 일치하는지, 또는 컨테이너 제한에 도달하는지 확인
  - **시스템 안정성**: 메모리 할당이 증가할 때 시스템이 비정상 종료(OOM, Out of Memory)되거나 속도가 느려지는지 관찰
  - **누적 효과**: allocated_memory 리스트에 데이터가 쌓이며 메모리 해제 전까지 사용량이 계속 증가하는지 체크
  - **컨테이너 제한 반영**: 컨테이너의 메모리 상한선에 도달하면 어떻게 반응하는지(예: 프로세스 종료, 제한 초과 등) 확인

```py
import os
import time
import numpy as np
import pandas as pd

def get_container_memory_usage():
    """컨테이너의 메모리 사용량 확인"""   

def memory_stress_test(start_size_mb=100, step_size_mb=100, max_steps=10, duration=10):
    """
    Parameters:
    start_size_mb (int): 시작 메모리 크기 (MB)
    step_size_mb (int): 단계별 증가 크기 (MB)
    max_steps (int): 최대 단계 수
    duration (int): 각 단계의 지속 시간 (초)
    """

if __name__ == "__main__":
    memory_stress_test(start_size_mb=8000, step_size_mb=100, max_steps=10, duration=5)
```

# 3. 디스크 부하 테스트

## 테스트 케이스

- 목표: 디스크 I/O를 점진적으로 증가시켜 Jupyter Notebook의 안정성 평가
- 방법: 큰 파일을 반복적으로 랜덤 데이터를 쓰고 읽는 작업을 수행
- 기준:
  - **읽기/쓰기 시간**: 파일 크기 증가에 따라 완료 시간이 어떻게 변하는지 확인하며, 특히 디스크 쓰기 속도의 한계를 관찰
  - **시스템 안정성**: 대용량 파일 I/O 중 시스템이 느려지거나 오류(예: 디스크 공간 부족)가 발생하는지 확인

```py
import os
import time
import psutil 

def disk_stress_test(start_size_mb=100, step_size_mb=100, max_steps=10, duration=30):
    """
    Parameters:
    start_size_mb (int): 시작 파일 크기 (MB)
    step_size_mb (int): 단계별 증가 크기 (MB)
    max_steps (int): 최대 단계 수
    duration (int): 각 단계의 지속 시간 (초)
    """

if __name__ == "__main__":
    disk_stress_test(start_size_mb=100, step_size_mb=100, max_steps=10, duration=5)
```

